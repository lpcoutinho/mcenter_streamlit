{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from pandas import json_normalize\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import math\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ACCESS_TOKEN_MUSICALCRIS = os.getenv(\"ACCESS_TOKEN_MUSICALCRIS\")\n",
    "SELLER_ID_MUSICALCRIS = os.getenv(\"SELLER_ID_MUSICALCRIS\")\n",
    "\n",
    "ACCESS_TOKEN_BUENOSHOPS = os.getenv(\"ACCESS_TOKEN_BUENOSHOPS\")\n",
    "SELLER_ID_BUENOSHOPS = os.getenv(\"SELLER_ID_BUENOSHOPS\")\n",
    "\n",
    "ACCESS_TOKEN_MCENTER = os.getenv(\"ACCESS_TOKEN_MCENTER\")\n",
    "SELLER_ID_MCENTER = os.getenv(\"SELLER_ID_MCENTER\")\n",
    "\n",
    "HOST = os.getenv(\"HOST\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "\n",
    "# Informações de conexão com o banco de dados PostgreSQL\n",
    "db_config = {\n",
    "    \"host\": HOST,\n",
    "    \"database\": POSTGRES_DB,\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(json_data, nome_arquivo):\n",
    "    \"\"\"\n",
    "    Escreve dados em um arquivo JSON, adicionando ao arquivo existente se ele já existir.\n",
    "\n",
    "    Parâmetros:\n",
    "    - json_data (list): Lista de dados em formato JSON a serem escritos no arquivo.\n",
    "    - nome_arquivo (str): Nome do arquivo onde os dados serão escritos ou adicionados.\n",
    "\n",
    "    Exemplo de uso:\n",
    "    ```python\n",
    "    json_list = [{'order_id': 1, 'product': 'Item 1'}, {'order_id': 2, 'product': 'Item 2'}]\n",
    "    write_file(json_list, 'orders.json')\n",
    "    ```\n",
    "\n",
    "    Se o arquivo já existir, os dados fornecidos serão adicionados aos dados existentes.\n",
    "    Se o arquivo não existir, um novo arquivo será criado e os dados serão escritos nele.\n",
    "    \"\"\"\n",
    "    if os.path.exists(nome_arquivo):\n",
    "        with open(nome_arquivo, \"r\") as arquivo_existente:\n",
    "            dados_existente = json.load(arquivo_existente)\n",
    "\n",
    "        dados_existente.extend(json_data)\n",
    "\n",
    "        with open(nome_arquivo, \"w\") as arquivo:\n",
    "            json.dump(dados_existente, arquivo)\n",
    "    else:\n",
    "        with open(nome_arquivo, \"w\") as arquivo:\n",
    "            json.dump(json_data, arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando dados de usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":648304687,\"nickname\":\"BUENO SONORIZAÇÃO\",\"registration_date\":\"2020-09-18T20:40:32.000-04:00\",\"first_name\":\"M A BUENO FREDERICO SONORIZACA\",\"last_name\":\"M A BUENO FREDERICO SONORIZACA\",\"gender\":\"\",\"country_id\":\"BR\",\"email\":\"mabuenosonorizacao@gmail.com\",\"identification\":{\"number\":\"37408559000165\",\"type\":\"CNPJ\"},\"address\":{\"address\":\"Rua Fernandes Pinheiro 168\",\"city\":\"Ponta Grossa\",\"state\":\"BR-PR\",\"zip_code\":\"84010135\"},\"phone\":{\"area_code\":\"42\",\"extension\":\"\",\"number\":\"30253124\",\"verified\":false},\"alternative_phone\":{\"area_code\":\"\",\"extension\":\"\",\"number\":\"\"},\"user_type\":\"brand\",\"tags\":[\"brand\",\"large_seller\",\"eshop\",\"mshops\",\"messages_as_seller\"],\"logo\":null,\"points\":163,\"site_id\":\"MLB\",\"permalink\":\"http://perfil.mercadolivre.com.br/BUENO+SONORIZA%C3%87%C3%83O\",\"seller_experience\":\"ADVANCED\",\"bill_data\":{\"accept_credit_note\":\"Y\"},\"seller_reputation\":{\"level_id\":\"5_green\",\"power_seller_status\":\"platinum\",\"transactions\":{\"canceled\":1053,\"completed\":24379,\"period\":\"historic\",\"ratings\":{\"negative\":0.16,\"neutral\":0.01,\"positive\":0.83},\"total\":25432},\"metrics\":{\"sales\":{\"period\":\"60 days\",\"completed\":5710},\"claims\":{\"period\":\"60 days\",\"rate\":0.0011,\"value\":7},\"delayed_handling_time\":{\"period\":\"60 days\",\"rate\":0,\"value\":0},\"cancellations\":{\"period\":\"60 days\",\"rate\":0.0005,\"value\":3}}},\"buyer_reputation\":{\"canceled_transactions\":0,\"tags\":[],\"transactions\":{\"canceled\":{\"paid\":null,\"total\":null},\"completed\":null,\"not_yet_rated\":{\"paid\":null,\"total\":null,\"units\":null},\"period\":\"historic\",\"total\":null,\"unrated\":{\"paid\":null,\"total\":null}}},\"status\":{\"billing\":{\"allow\":true,\"codes\":[]},\"buy\":{\"allow\":true,\"codes\":[],\"immediate_payment\":{\"reasons\":[],\"required\":false}},\"confirmed_email\":true,\"shopping_cart\":{\"buy\":\"allowed\",\"sell\":\"allowed\"},\"immediate_payment\":false,\"list\":{\"allow\":true,\"codes\":[],\"immediate_payment\":{\"reasons\":[],\"required\":false}},\"mercadoenvios\":\"not_accepted\",\"mercadopago_account_type\":\"personal\",\"mercadopago_tc_accepted\":true,\"required_action\":null,\"sell\":{\"allow\":true,\"codes\":[],\"immediate_payment\":{\"reasons\":[],\"required\":false}},\"site_status\":\"active\",\"user_type\":\"simple_registration\"},\"secure_email\":\"mmabuen.jbz7dfj@mail.mercadolivre.com\",\"company\":{\"brand_name\":\"M A BUENO FREDERICO SONORIZACA\",\"city_tax_id\":\"\",\"corporate_name\":\"M. A. BUENO FREDERICO SONORIZACAO LTDA\",\"identification\":\"37408559000165\",\"state_tax_id\":\"9085061035\",\"cust_type_id\":\"BU\",\"soft_descriptor\":\"BUENOSONORIZA\"},\"credit\":{\"consumed\":6780.8,\"credit_level_id\":\"MLB1\",\"rank\":\"premium\"},\"context\":{\"device\":\"web-desktop\",\"flow\":\"company\",\"ip_address\":\"138.204.27.98\",\"source\":\"mercadolivre\"},\"registration_identifiers\":[]}\n"
     ]
    }
   ],
   "source": [
    "#### Verificando dados de usuário\n",
    "url = \"https://api.mercadolibre.com/users/me\"\n",
    "\n",
    "payload = {}\n",
    "# headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_BUENOSHOPS}\"}\n",
    "# headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_MUSICALCRIS}\"}\n",
    "headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_BUENOSHOPS}\"}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "response = response.text\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_list = []\n",
    "len(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter dados para um intervalo de datas específico\n",
    "def get_orders_for_date_range(date_from, date_to, offset=0, limit=50):\n",
    "    base_url = \"https://api.mercadolibre.com/orders/search\"\n",
    "\n",
    "    params = {\n",
    "        \"seller\": f\"{SELLER_ID_BUENOSHOPS}\",\n",
    "        # \"seller\": f\"{SELLER_ID_MCENTER}\",\n",
    "        \"order.date_closed.from\": f\"{date_from}T00:00:00.000-03:00\",\n",
    "        \"order.date_closed.to\": f\"{date_to}T00:00:00.000-03:00\",\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset,\n",
    "    }\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_BUENOSHOPS}\"}\n",
    "    # headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_MCENTER}\"}\n",
    "\n",
    "    # json_list = []\n",
    "    counter = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            response = requests.get(base_url, params=params, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if \"results\" in data:\n",
    "                json_list.extend(data[\"results\"])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            if \"paging\" in data:\n",
    "                total_paging = data[\"paging\"].get(\"total\")\n",
    "                if total_paging is None:\n",
    "                    break\n",
    "\n",
    "                total_pages = math.ceil(total_paging / params[\"limit\"])\n",
    "                print(f\"Total esperado de páginas: {counter + 1}/{total_pages}\")\n",
    "                print(f\"Total de dados esperados: {total_paging}\")\n",
    "                print(f'Offset atual: {params[\"offset\"]}')\n",
    "                print(f\"Intervalo de datas atual: {date_from} - {date_to}\")\n",
    "\n",
    "                if params[\"offset\"] > total_paging:\n",
    "                    break\n",
    "\n",
    "                params[\"offset\"] += params[\"limit\"]\n",
    "                counter += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"Erro ao fazer a requisição para {base_url}: {req_err}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro não esperado: {e}\")\n",
    "\n",
    "    print(f\"Total de dados coletados para {date_from} - {date_to}: {len(json_list)}\")\n",
    "    return json_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total esperado de páginas: 1/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 0\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 2/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 50\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 3/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 100\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 4/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 150\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 5/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 200\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 6/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 250\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 7/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 300\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 8/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 350\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 9/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 400\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 10/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 450\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total esperado de páginas: 11/10\n",
      "Total de dados esperados: 485\n",
      "Offset atual: 500\n",
      "Intervalo de datas atual: 2023-12-6 - 2023-12-12\n",
      "Total de dados coletados para 2023-12-6 - 2023-12-12: 485\n",
      "Progresso: 1/1 (100.00%)\n",
      "Total de dados coletados para todos os intervalos: 970\n",
      "Número total de iterações: 1\n",
      "Número de iterações bem-sucedidas: 1\n",
      "Número de iterações falhadas: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir os intervalos de datas desejados\n",
    "date_ranges = [\n",
    "    (\"2023-12-6\", \"2023-12-12\"),\n",
    "    # Adicione mais intervalos conforme necessário\n",
    "]\n",
    "\n",
    "json_list = []  # Certifique-se de iniciar a lista\n",
    "\n",
    "success_count = 0\n",
    "total_iterations = len(date_ranges)\n",
    "\n",
    "# Executar a função para cada intervalo de datas\n",
    "for index, date_range in enumerate(date_ranges, start=1):\n",
    "    date_from, date_to = date_range\n",
    "\n",
    "    json_data = get_orders_for_date_range(date_from, date_to)\n",
    "\n",
    "    if json_data:\n",
    "        json_list.extend(json_data)\n",
    "        success_count += 1\n",
    "\n",
    "    # Exibir o progresso\n",
    "    progress_percentage = (index / total_iterations) * 100\n",
    "    print(f\"Progresso: {index}/{total_iterations} ({progress_percentage:.2f}%)\")\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"Total de dados coletados para todos os intervalos: {len(json_list)}\")\n",
    "print(f\"Número total de iterações: {total_iterations}\")\n",
    "print(f\"Número de iterações bem-sucedidas: {success_count}\")\n",
    "print(f\"Número de iterações falhadas: {total_iterations - success_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n"
     ]
    }
   ],
   "source": [
    "print(len(json_list))\n",
    "# json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(json_list, \"../../Data/Output/cris_orders.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../../Data/Output/bueno_orders.json\", \"r\") as file:\n",
    "#     json_list = json.load(file)\n",
    "\n",
    "# len(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando dados de orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_code</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_id</th>\n",
       "      <th>shipping_id</th>\n",
       "      <th>pack_id</th>\n",
       "      <th>title</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>seller_sku</th>\n",
       "      <th>quantity</th>\n",
       "      <th>variation_name</th>\n",
       "      <th>variation_attributes_id</th>\n",
       "      <th>variation_value_id</th>\n",
       "      <th>variation_value_name</th>\n",
       "      <th>date_approved</th>\n",
       "      <th>date_closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>MLB2680948743</td>\n",
       "      <td>approved</td>\n",
       "      <td>paid</td>\n",
       "      <td>2000007094505718</td>\n",
       "      <td>42885330464</td>\n",
       "      <td>0</td>\n",
       "      <td>Ukulele Concert Winner 23 Sapele Cordas Aquila By Kalani</td>\n",
       "      <td>174653391986</td>\n",
       "      <td>MLB202371</td>\n",
       "      <td>FULLC4WINNER11023</td>\n",
       "      <td>1</td>\n",
       "      <td>Cor</td>\n",
       "      <td>COLOR</td>\n",
       "      <td>52005</td>\n",
       "      <td>Marrom</td>\n",
       "      <td>2023-12-08 15:19:11</td>\n",
       "      <td>2023-12-08 15:20:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ml_code payment_status order_status          order_id  shipping_id  \\\n",
       "249  MLB2680948743       approved         paid  2000007094505718  42885330464   \n",
       "\n",
       "     pack_id                                                     title  \\\n",
       "249        0  Ukulele Concert Winner 23 Sapele Cordas Aquila By Kalani   \n",
       "\n",
       "     variation_id category_id         seller_sku  quantity variation_name  \\\n",
       "249  174653391986   MLB202371  FULLC4WINNER11023         1            Cor   \n",
       "\n",
       "    variation_attributes_id variation_value_id variation_value_name  \\\n",
       "249                   COLOR              52005               Marrom   \n",
       "\n",
       "          date_approved         date_closed  \n",
       "249 2023-12-08 15:19:11 2023-12-08 15:20:11  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = []\n",
    "\n",
    "for item in json_list:\n",
    "    # Extrair os valores desejados\n",
    "    payments = item.get(\"payments\", [])\n",
    "    status = item[\"status\"]\n",
    "    date_closed = item[\"date_closed\"]\n",
    "    pack_id = item[\"pack_id\"]\n",
    "    shipping = item[\"shipping\"]\n",
    "    order_items = item.get(\"order_items\", [])\n",
    "    fulfilled = item[\"fulfilled\"]\n",
    "\n",
    "    for payment in payments:\n",
    "        order_id = payment[\"order_id\"]\n",
    "        reason = payment[\"reason\"]\n",
    "        payment_status = payment[\"status\"]\n",
    "        date_approved = payment[\"date_approved\"]\n",
    "\n",
    "    # Inicializa variável para armazenar shipping_id\n",
    "    shipping_id = None\n",
    "    shipping_id = shipping[\"id\"]\n",
    "\n",
    "    # # Inicializa listas para armazenar informações específicas de order_items\n",
    "\n",
    "    # Itera sobre os dicionários em order_items\n",
    "    for order_item in order_items:\n",
    "        item_info = order_item.get(\"item\", {})\n",
    "        # item_id = item_info.get(\"id\")\n",
    "        ml_code = item_info[\"id\"]\n",
    "        title = item_info[\"title\"]\n",
    "        variation_id = item_info[\"variation_id\"]\n",
    "        seller_sku = item_info[\"seller_sku\"]\n",
    "        quantity = order_item[\"quantity\"]\n",
    "        category_id = item_info[\"category_id\"]\n",
    "\n",
    "        variation_attributes = item_info.get(\"variation_attributes\", [])\n",
    "\n",
    "        name = None\n",
    "        value_id = None\n",
    "        value_name = None\n",
    "        for attribute in variation_attributes:\n",
    "            name = attribute[\"name\"]\n",
    "            id = attribute[\"id\"]\n",
    "            value_id = attribute[\"value_id\"]\n",
    "            value_name = attribute[\"value_name\"]\n",
    "\n",
    "    # Adicionar os resultados à lista\n",
    "    resultados.append(\n",
    "        {\n",
    "            # \"payments\": payments,\n",
    "            \"ml_code\": ml_code,\n",
    "            \"payment_status\": payment_status,\n",
    "            \"order_status\": status,\n",
    "            \"order_id\": order_id,\n",
    "            \"shipping_id\": shipping_id,\n",
    "            \"pack_id\": pack_id,\n",
    "            \"title\": title,\n",
    "            \"variation_id\": variation_id,\n",
    "            \"category_id\": category_id,\n",
    "            \"seller_sku\": seller_sku,\n",
    "            \"quantity\": quantity,\n",
    "            \"variation_name\": name,\n",
    "            \"variation_attributes_id\": id,\n",
    "            \"variation_value_id\": value_id,\n",
    "            \"variation_value_name\": value_name,\n",
    "            \"date_approved\": date_approved,\n",
    "            \"date_closed\": date_closed,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Exibir os resultados\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "df = pd.DataFrame(resultados)\n",
    "\n",
    "# Tratando dados numéricos\n",
    "pd.set_option(\"display.float_format\", \"{:.0f}\".format)\n",
    "df[\"shipping_id\"] = df[\"shipping_id\"].fillna(0)\n",
    "df[\"pack_id\"] = df[\"pack_id\"].fillna(0)\n",
    "df[\"variation_id\"] = df[\"variation_id\"].fillna(0)\n",
    "df[\"shipping_id\"] = df[\"shipping_id\"].astype(\"int64\")\n",
    "df[\"pack_id\"] = df[\"pack_id\"].astype(\"int64\")\n",
    "df[\"variation_id\"] = df[\"variation_id\"].astype(\"int64\")\n",
    "\n",
    "\n",
    "# Adiciona 1h a mais para chegar ao horário do Brasil\n",
    "df[\"date_approved\"] = pd.to_datetime(df[\"date_approved\"])\n",
    "df[\"date_closed\"] = pd.to_datetime(df[\"date_closed\"])\n",
    "df[\"date_approved\"] = df[\"date_approved\"] + pd.to_timedelta(\"1 hour\")\n",
    "df[\"date_approved\"] = df[\"date_approved\"].dt.tz_localize(None)\n",
    "df[\"date_closed\"] = df[\"date_closed\"] + pd.to_timedelta(\"1 hour\")\n",
    "df[\"date_closed\"] = df[\"date_closed\"].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df.sample(1)\n",
    "# df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando logistic type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "json_logistic_list = []\n",
    "success_count = 0\n",
    "\n",
    "total_iterations = len(df[\"shipping_id\"])\n",
    "for index, shipping_id in enumerate(df[\"shipping_id\"], start=1):\n",
    "    url = f\"https://api.mercadolibre.com/shipments/{shipping_id}\"\n",
    "\n",
    "    # headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_BUENOSHOPS}\"}\n",
    "    # headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_MUSICALCRIS}\"}\n",
    "    headers = {\"Authorization\": f\"Bearer {ACCESS_TOKEN_MCENTER}\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        json_data = response.json()\n",
    "        json_logistic_list.append(json_data)\n",
    "        success_count += 1\n",
    "        print(f\"Obtido com sucesso para shipping_id {shipping_id}: {json_data}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro ao obter dados para shipping_id {shipping_id}: {e}\")\n",
    "\n",
    "    # time.sleep(5)\n",
    "\n",
    "    # Exibir o progresso\n",
    "    progress_percentage = (index / total_iterations) * 100\n",
    "    print(f\"Progresso: {index}/{total_iterations} ({progress_percentage:.2f}%)\")\n",
    "\n",
    "# Exibir os resultados\n",
    "print(json_logistic_list)\n",
    "\n",
    "# Exibir estatísticas de conclusão\n",
    "print(f\"Número total de iterações: {total_iterations}\")\n",
    "print(f\"Número de iterações bem-sucedidas: {success_count}\")\n",
    "print(f\"Número de iterações falhadas: {total_iterations - success_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(json_logistic_list))\n",
    "print(len(json_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_logistic_list) == len(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_file(json_logistic_list, \"../../Data/Output/bueno_shipping.json\")\n",
    "# write_file(json_logistic_list, \"../../Data/Output/musicalsris_shipping.json\")\n",
    "write_file(json_logistic_list, \"../../Data/Output/mucenter_shipping.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../../Data/Output/shipping.json\", \"r\") as file:\n",
    "# # with open(\"orders_05_06.json\", \"r\") as file:\n",
    "#     json_logistic_list = json.load(file)\n",
    "\n",
    "# len(json_logistic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando logistic_type ao df principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(json_logistic_list)\n",
    "# cols = ['id', 'order_id', 'logistic_type']\n",
    "cols = [\"id\", \"logistic_type\"]\n",
    "dfx = dfx[cols]\n",
    "# dfx['id'].value_counts()\n",
    "\n",
    "print(dfx.shape)\n",
    "dfx.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um dicionário a partir de dfx para mapear 'order_id' para 'logistic_type'\n",
    "order_id_to_logistic_type = dfx.set_index(\"id\")[\"logistic_type\"].to_dict()\n",
    "\n",
    "# Adicionar a coluna 'logistic_type' a df usando o mapeamento\n",
    "df_result = df.copy()  # Criar uma cópia de df para manter o original intacto\n",
    "df_result[\"logistic_type\"] = df_result[\"shipping_id\"].map(order_id_to_logistic_type)\n",
    "\n",
    "print(df_result.shape)\n",
    "df_result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df_result[df_result['shipping_id'] == 42782133490]\n",
    "# x = df_result[df_result['ml_code'] == 'MLB4166151108']\n",
    "# x = df_result[df_result['order_id'] == 2000006859129842]\n",
    "x = df_result[pd.isna(df_result[\"logistic_type\"])]\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[[\"order_id\", \"shipping_id\", \"pack_id\", \"variation_id\"]] = df_result[\n",
    "    [\"order_id\", \"shipping_id\", \"pack_id\", \"variation_id\"]\n",
    "].astype(str)\n",
    "df_result[[\"order_id\", \"shipping_id\", \"pack_id\", \"variation_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populando tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"variation_attributes_id\"] = df_result[\"variation_attributes_id\"].replace(\n",
    "    \"<built-in function id>\", None, inplace=True\n",
    ")\n",
    "\n",
    "df_result[df_result[\"ml_code\"] == \"MLB1991060554\"]\n",
    "df_result[df_result[\"order_id\"] == \"2000006887872016\"]\n",
    "# df[df['ml_code']=='MLB1991060554']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(**db_config)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in df_result.iterrows():\n",
    "    # for index, row in df_resultado.iterrows():\n",
    "    \n",
    "    # insert_query = sql.SQL(\n",
    "    #     \"INSERT INTO bueno_ml_orders (ml_code,category_id,variation_id,seller_sku,order_id,pack_id,quantity,title,order_status,payment_status,variation_name,variation_attributes_id,variation_value_id,variation_value_name,shipping_id,date_approved,date_closed,logistic_type) VALUES (%s, %s, %s, %s,%s, %s, %s,%s, %s, %s,%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    # )\n",
    "    # print(\"Inserindo dados:\", [value for value in row])\n",
    "    \n",
    "    # insert_query = sql.SQL(\n",
    "    #     \"INSERT INTO cris_ml_orders (ml_code,category_id,variation_id,seller_sku,order_id,pack_id,quantity,title,order_status,payment_status,variation_name,variation_attributes_id,variation_value_id,variation_value_name,shipping_id,date_approved,date_closed,logistic_type) VALUES (%s, %s, %s, %s,%s, %s, %s,%s, %s, %s,%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    # )\n",
    "    # print(\"Inserindo dados:\", [value for value in row])\n",
    "    \n",
    "    # print(\"Tipos de dados dos valores:\", [type(value) for value in row])\n",
    "    \n",
    "    insert_query = sql.SQL(\n",
    "        \"INSERT INTO mcenter_ml_orders (ml_code,category_id,variation_id,seller_sku,order_id,pack_id,quantity,title,order_status,payment_status,variation_name,variation_attributes_id,variation_value_id,variation_value_name,shipping_id,date_approved,date_closed,logistic_type) VALUES (%s, %s, %s, %s,%s, %s, %s,%s, %s, %s,%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "    )\n",
    "    print(\"Inserindo dados:\", [value for value in row])\n",
    "    \n",
    "    cursor.execute(\n",
    "        insert_query,\n",
    "        (\n",
    "            row[\"ml_code\"],\n",
    "            row[\"category_id\"],\n",
    "            row[\"variation_id\"],\n",
    "            row[\"seller_sku\"],\n",
    "            row[\"order_id\"],\n",
    "            row[\"pack_id\"],\n",
    "            row[\"quantity\"],\n",
    "            row[\"title\"],\n",
    "            row[\"order_status\"],\n",
    "            row[\"payment_status\"],\n",
    "            row[\"variation_name\"],\n",
    "            row[\"variation_attributes_id\"],\n",
    "            row[\"variation_value_id\"],\n",
    "            row[\"variation_value_name\"],\n",
    "            row[\"shipping_id\"],\n",
    "            row[\"date_approved\"],\n",
    "            row[\"date_closed\"],\n",
    "            row[\"logistic_type\"],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Feche o cursor e a conexão\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Dados inseridos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
